{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "\n",
    "from fimodemix.utils.experiment_files import ExperimentsFiles\n",
    "\n",
    "from fimodemix.configs.config_classes.fim_sde_config import FIMSDEpModelParams\n",
    "from fimodemix.data.datasets import FIMSDEpDatabatchTuple\n",
    "from fimodemix.data.dataloaders import FIMSDEpDataLoader\n",
    "from fimodemix.models.fim_sdep import FIMSDEp\n",
    "from fimodemix.utils.grids import define_mesh_points,define_mask\n",
    "\n",
    "from fimodemix.data.generation_sde import constant_diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the experiment dir where everything is located\n",
    "experiment_dir = r\"C:\\Users\\cesar\\Desktop\\Projects\\FoundationModels\\fimodemix\\results\\1729141498\"\n",
    "experiment_files = ExperimentsFiles(experiment_dir,delete=False)\n",
    "checkpoint_path = experiment_files.get_lightning_checkpoint_path(\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cesar\\anaconda3\\envs\\fimode\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\users\\cesar\\desktop\\projects\\foundationmodels\\fimodemix\\src\\fimodemix\\data\\datasets.py:96: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data: FIMSDEpDatabatch = torch.load(file_path)  # Adjust loading method as necessary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Hypercube Size: 1024\n",
      "Max Dimension: 3\n",
      "Max Num Steps: 129\n",
      "Max Hypercube Size: 1024\n",
      "Max Dimension: 3\n",
      "Max Num Steps: 129\n",
      "Max Hypercube Size: 1024\n",
      "Max Dimension: 3\n",
      "Max Num Steps: 129\n"
     ]
    }
   ],
   "source": [
    "# load parameters and model\n",
    "params = FIMSDEpModelParams.from_yaml(experiment_files.params_yaml)\n",
    "model = FIMSDEp.load_from_checkpoint(checkpoint_path).to(torch.device(\"cpu\"))\n",
    "dataloaders = FIMSDEpDataLoader(params)\n",
    "databatch = dataloaders.one_batch\n",
    "X = databatch.hypercube_locations[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#mask = define_mask(X,databatch)\n",
    "#grid_d = define_mesh_points(total_points=num_grid_points,n_dims=2)\n",
    "#all_grid = torch.zeros(X.size(0),1024,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "from torch import Tensor\n",
    "from typing import Tuple\n",
    "from fimodemix.data.generation_sde import constant_diffusion\n",
    "\n",
    "def model_as_drift_n_diffusion(\n",
    "        model:FIMSDEp,\n",
    "        X:Tensor,\n",
    "        time:Tensor=None,\n",
    "        databatch:FIMSDEpDatabatchTuple=None\n",
    "    )->Tuple[Tensor,Tensor]:\n",
    "    \"\"\"\n",
    "    Defines the drift and the diffusion from the forward pass\n",
    "    and handles the padding accordingly \n",
    "\n",
    "    Args:\n",
    "        X (Tensor[B,D]): state \n",
    "        time: (None)\n",
    "        databatch (FIMSDEpDatabatchTuple):\n",
    "    Returns:\n",
    "        drift,diffusion\n",
    "    \"\"\"\n",
    "    D = X.size(1)\n",
    "    B = X.size(0)\n",
    "    X = X.unsqueeze(1) \n",
    "    drift = model(databatch,X).squeeze()\n",
    "    diffusion = constant_diffusion(X.squeeze(),None,databatch.diffusion_parameters)\n",
    "    # Create a mask based on the dimensions\n",
    "    mask = torch.arange(D, device=X.device).expand(B, -1) < databatch.process_dimension  # Shape [B, D]\n",
    "    # Apply the mask to X\n",
    "    drift = drift * mask.float()  # Zero out elements where mask is False\n",
    "    diffusion = diffusion * mask.float()  # Zero out elements where mask is False\n",
    "    return drift,diffusion\n",
    "\n",
    "def model_euler_maruyama_step(states,dt,model:FIMSDEp,databatch:FIMSDEpDatabatchTuple):\n",
    "    \"\"\"\n",
    "    Assumes diagonal diffusion \n",
    "     \n",
    "    Args:\n",
    "        states (Tensor[B,D])\n",
    "        dt (float)\n",
    "        model (FIMSDEp)\n",
    "        databatch (databatch)\n",
    "    Returns:\n",
    "        new_states(Tensor[B,D])\n",
    "    \"\"\"\n",
    "    # Calculate the deterministic part\n",
    "    drift,diffusion = model_as_drift_n_diffusion(model,states,None,databatch)\n",
    "    # Update the state with the deterministic part\n",
    "    new_states = states + drift * dt\n",
    "    # Add the diffusion part\n",
    "    new_states += diffusion * torch.sqrt(torch.tensor(dt)) * torch.randn_like(states)\n",
    "    return new_states\n",
    "\n",
    "def model_euler_maruyama_loop(\n",
    "        num_steps: int = 100,\n",
    "        dt: float = 0.01,\n",
    "        model: FIMSDEp = None,\n",
    "        databatch: FIMSDEpDatabatchTuple = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulates paths from the Model using the Euler-Maruyama method.\n",
    "\n",
    "    This is highly costly as the method needs to calculate a forward pass \n",
    "    per Euler Mayorama Step\n",
    "\n",
    "    Args:\n",
    "        num_steps: int = 100,\n",
    "        dt: float = 0.01,\n",
    "        model: FIMSDEp = None,\n",
    "        databatch: FIMSDEpDatabatchTuple = None,\n",
    "    Returns:\n",
    "        paths(Tensor[B,number_of_steps,D]),times([B,number_of_steps,D])\n",
    "\n",
    "    \"\"\"\n",
    "    dimensions = databatch.obs_values.size(2)\n",
    "    num_paths = databatch.obs_values.size(0)\n",
    "    \n",
    "    # Initialize states for all paths\n",
    "    states = torch.nn.functional.sigmoid(torch.normal(0., 1., size=(num_paths, dimensions)))\n",
    "\n",
    "    # Store paths\n",
    "    paths = torch.zeros((num_paths, num_steps + 1, dimensions))  # +1 for initial state\n",
    "    paths[:, 0] = states.clone()  # Store initial states\n",
    "\n",
    "    times = torch.linspace(0., num_steps * dt, num_steps + 1)\n",
    "    times = times[None, :].repeat(num_paths, 1)\n",
    "\n",
    "    # Simulate the paths with tqdm progress bar\n",
    "    for step in tqdm(range(num_steps), desc=\"Simulating steps\", unit=\"step\"):\n",
    "        states = model_euler_maruyama_step(states, dt, model, databatch)  # Diffusion term\n",
    "        paths[:, step + 1] = states.clone()  # Store new states\n",
    "\n",
    "    return paths,times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating steps:   0%|          | 0/100 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating steps: 100%|██████████| 100/100 [00:04<00:00, 21.89step/s]\n"
     ]
    }
   ],
   "source": [
    "paths = model_euler_maruyama_loop(100,0.01,model,databatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fimode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
